{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10772930,"sourceType":"datasetVersion","datasetId":6683492}],"dockerImageVersionId":30886,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"from sklearn.datasets import load_breast_cancer\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import accuracy_score, classification_report\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:54:19.443979Z","iopub.execute_input":"2025-02-17T11:54:19.444483Z","iopub.status.idle":"2025-02-17T11:54:19.451766Z","shell.execute_reply.started":"2025-02-17T11:54:19.444452Z","shell.execute_reply":"2025-02-17T11:54:19.449367Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/rfr-data/loan_data.csv')\ndata.head()\ndf = pd.DataFrame(data)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:54:19.459400Z","iopub.execute_input":"2025-02-17T11:54:19.459715Z","iopub.status.idle":"2025-02-17T11:54:19.576017Z","shell.execute_reply.started":"2025-02-17T11:54:19.459692Z","shell.execute_reply":"2025-02-17T11:54:19.574998Z"}},"outputs":[],"execution_count":46},{"cell_type":"markdown","source":"**The function is used to define the categorical values in the dataset, then perform LabelEncoding on them which is a popular way of preproccessing the categorical values before model training.**# ","metadata":{}},{"cell_type":"code","source":"def encode_categorical_features(df):\n    categorical_cols = df.select_dtypes(include=['object']).columns.tolist()\n    print(f'The categorical values found are: {categorical_cols}')\n\n    label_encoders = {}\n    \n    for col in categorical_cols:\n        encoder = LabelEncoder()\n        df[col] = encoder.fit_transform(df[col])\n        label_encoders[col] = encoder\n    return df, label_encoders\n\nencoded_df, encoders = encode_categorical_features(df)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T11:54:19.577346Z","iopub.execute_input":"2025-02-17T11:54:19.577646Z","iopub.status.idle":"2025-02-17T11:54:19.637517Z","shell.execute_reply.started":"2025-02-17T11:54:19.577621Z","shell.execute_reply":"2025-02-17T11:54:19.636247Z"}},"outputs":[{"name":"stdout","text":"The categorical values found are: ['person_gender', 'person_education', 'person_home_ownership', 'loan_intent', 'previous_loan_defaults_on_file']\n","output_type":"stream"}],"execution_count":47},{"cell_type":"markdown","source":"\nThe train_test_split function splits the data into a training set (70%) and a testing set (30%), with a fixed random state for reproducibility\n\nOn one side we get to use the regressor model without the bootstrap enabled and the other with it enaled.\n\nonce trained we can use both models to make predictions on the data","metadata":{}},{"cell_type":"code","source":"X = df.drop('loan_status', axis = 1)\ny = df['loan_status']\nX_train,X_test, y_train,y_test = train_test_split(X,y, test_size = 0.3, random_state = 42)\nst\n\nregressor_bootstrap_disabled = RandomForestRegressor(n_estimators = 10, random_state =0, bootstrap = False)\nregressor = RandomForestRegressor(n_estimators = 10, random_state =0)\nregressor_bootstrap_disabled.fit(X_train,y_train)\nregressor.fit(X_train,y_train)\n\ny_pred_bootstrap_disabled = regressor_bootstrap_disabled.predict(X_test)\ny_pred_= regressor.predict(X_test)\n\ny_pred_bootstrap_disabled_int = y_pred.astype(int)\ny_pred = y_pred.astype(int)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:04:34.758974Z","iopub.execute_input":"2025-02-17T12:04:34.759368Z","iopub.status.idle":"2025-02-17T12:04:36.921839Z","shell.execute_reply.started":"2025-02-17T12:04:34.759339Z","shell.execute_reply":"2025-02-17T12:04:36.920828Z"}},"outputs":[],"execution_count":61},{"cell_type":"markdown","source":"After making predictions with the Random Forest model where bootstrap sampling is disabled, we evaluate its accuracy using the accuracy_score function, which compares the predicted values.\n\nThe model's accuracy is then printed as a percentage. Additionally, we use the classification_report function to generate a detailed performance report that includes key metrics such as precision, recall, and F1-score for each class in the loan status prediction task, providing deeper insight into how well the model performs across different aspects of the classification task.","metadata":{}},{"cell_type":"code","source":"Model_accuracy_bootstrap_disabled = accuracy_score(y_test,y_pred_bootstrap_disabled_int)\nprint(f'The models accuracy when bootstrap  is diabled: {Model_accuracy_bootstrap_disabled * 100:.2f}')\nprint(\"\\nClassification_report\")\nprint(classification_report(y_test,y_pred_bootstrap_disabled_int))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:06:19.543943Z","iopub.execute_input":"2025-02-17T12:06:19.544421Z","iopub.status.idle":"2025-02-17T12:06:19.585035Z","shell.execute_reply.started":"2025-02-17T12:06:19.544390Z","shell.execute_reply":"2025-02-17T12:06:19.582685Z"}},"outputs":[{"name":"stdout","text":"The models accuracy when bootstrap  is diabled: 88.54\n\nClassification_report\n              precision    recall  f1-score   support\n\n           0       0.87      1.00      0.93     10493\n           1       0.99      0.49      0.66      3007\n\n    accuracy                           0.89     13500\n   macro avg       0.93      0.74      0.79     13500\nweighted avg       0.90      0.89      0.87     13500\n\n","output_type":"stream"}],"execution_count":64},{"cell_type":"code","source":"Model_accuracy = accuracy_score(y_test,y_pred)\nprint(f'The models accuracy is: {Model_accuracy * 100:.2f}')\nprint(\"\\nClassification_report\")\nprint(classification_report(y_test,y_pred ))\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-02-17T12:06:39.906340Z","iopub.execute_input":"2025-02-17T12:06:39.906668Z","iopub.status.idle":"2025-02-17T12:06:39.944472Z","shell.execute_reply.started":"2025-02-17T12:06:39.906644Z","shell.execute_reply":"2025-02-17T12:06:39.943229Z"}},"outputs":[{"name":"stdout","text":"The models accuracy is: 88.54\n\nClassification_report\n              precision    recall  f1-score   support\n\n           0       0.87      1.00      0.93     10493\n           1       0.99      0.49      0.66      3007\n\n    accuracy                           0.89     13500\n   macro avg       0.93      0.74      0.79     13500\nweighted avg       0.90      0.89      0.87     13500\n\n","output_type":"stream"}],"execution_count":65},{"cell_type":"markdown","source":"Here we can observe that there was negligable change in the thus we can observe that the data was clean, contained no missing data and was generally distributed well","metadata":{}},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}